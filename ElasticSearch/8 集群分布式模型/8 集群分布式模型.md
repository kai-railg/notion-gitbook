# 8 集群分布式模型

- 分布式模型
    - 一台单机master node
    - 多台master eligible node
- 选主和脑裂
    - 选主
        - 集群第一台启动的机器默认为master
        - 互相 Ping多方，Node Id小的机器获得一个选票，Node Id 最小的机器获得最多选票，当选master Node
    - 脑裂
        - 当出现网络问题，一个节点和其他节点无法连接，该节点会自己选为Master，其他节点同样会选出一个Master，更新 Cluster state。当网络恢复时，两个Master 无法维护正确的集群信息
        - 设置 `quorum` 仲裁，只有当Master eligible Node 大于 quorum 数量的时候，才能选举
            - 7.0 开始，ES默认设置

- 分片故障转移
    - 步骤
    - 三台Node，三个主分片（P），三个副本分片（R）
        - 图为当Node1 挂掉时，主分转移的过程

    ![8%20%E9%9B%86%E7%BE%A4%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%9E%8B%200c15fddde6b042ebb8a409abcafd2e72/Untitled.png](8%20%E9%9B%86%E7%BE%A4%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%9E%8B%200c15fddde6b042ebb8a409abcafd2e72/Untitled.png)

- 文档到分片的映射算法
    - 随机 / Round Robin
    - 维护文档到分片的映射关系
    - 实时计算
    - 文档到分片的路由算法
        - hash(routing_id) % 主分片数
            - 默认的routing_id是文档的ID
            - 这也是主分片数为什么不能修改的根本原因
- 分片的生命周期
    - 分片是有倒排索引文件组成的，倒排索引文件的写入过程
        - `Segment → Index buffer → Refresh → Cache+Transaction -> Flush → Merge`
    - Lucene 中，单个倒排索引文件被称为 Segment。
        - `Segment` 是不可变更的
        - 多个Segment汇总在一起，就是 `Lucene Index`。对应ES的分片。
        - 当有新文件写入时，会生成新的Segment。查询时会查询所有Segment文件，并对结果汇总。
        - 删除的文档信息，保存在 .del文件中。查询时对其进行过滤。
            - 这是为什么ES删除文档后不会马上释放空间的原因。
        - Lucene 中有一个文件，用来记录所有Segment信息。称作 Commit Point。
    - 将 Index buffer 写入Segment的过程叫 `Refresh`
        - Refresh 默认频率 1秒一次
            - 这是为什么ES被称为近实时搜索的原因。
        - Index buffer 被占满时，会触发Refresh。默认是 JVM的 10%。
    - Segment 写入磁盘的过程相对耗时
        - 首先借助文件系统缓存，Refresh 时，先将`Segment写入缓存`以开放查询
        - 为了保证数据不丢失，Index文件时，同时写 `Transaction Log`
            - 每个分片有一个`Transaction Log`
        - Refresh 时，Index buffer会被清空，Transaction Log 不会被清空
        - 针对 Transaction Log 的 `Flush`
            - 首先调用 Refresh，清空 Index buffer
            - 调用 fsync，将缓存中Segment写入磁盘
            - 清空  Transaction Log
                - 当 Transaction Log满（默认512G），也会调用 Flush
    - Segment 的 合并 `Merge`
        - 当Segment写入磁盘后，随着Segment的越来越多，需要被定期合并
            - 手动执行merge操作 `POST my_index/_forcemerge`

     

- 分布式搜索的内部机制
    - ES的搜索，分为两阶段进行
        - Query
            - 请求到ES节点后，收到请求的节点会以Cooidating 节点的身份，在全部主副分片中随机选择N个，发送查询请求
            - 被选中的分片执行查询，进行排序。每个分片都会返回 `from + size` 个排序后的 `文档ID`和`排序值`给 Coordating 。
        - Fetch
            - Coordating Node 会将 Query阶段收到的查询结果重新排序。选取 from+size个文档
            - 以 multi get 的方式，到相应的分片获取详细的文档数据
    - 存在的问题
        - 性能问题
            - 每个分片需要查询 from+size个文档
            - Coordating Node需要处理 `分片数 *  from+size个文档`
            - 深度分页
        - 相关性算分
            - 相关性算分在分片之间是相互独立的，每个分片都基于自己分片上的数据进行算分，这会导致`算分偏离`的问题
                - 比如文档数量很少，主分片数量很多时
            - 解决算分不准的方法
                - 数据量不大时，主分片设置为1
                - DFS Query
                    - 搜索时指定 `_search?search_type=dfs_query_the_fetch`
                    - 到每个分片把各分片的词频和文档频率进行搜集，进行完整的算法
                    - 耗费更多的CPU和内存
            - 
- 排序
    - ES默认根据算分进行排序，但是可以指定字段进行排序，也可以多字段排序
    - 排序是针对原始字段进行的，倒排索引无法发挥作用
        - 需要正排索引
    - ES有两种排序方式
        - Fielddata
        - Doc Values（列式存储，对Text类型无效）
            - 默认打开，如果明确不做排序及聚合分析，可以关闭

        ![8%20%E9%9B%86%E7%BE%A4%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%9E%8B%200c15fddde6b042ebb8a409abcafd2e72/Untitled%201.png](8%20%E9%9B%86%E7%BE%A4%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%9E%8B%200c15fddde6b042ebb8a409abcafd2e72/Untitled%201.png)

- 分页与遍历
    - 深度分页的问题
        - ES是分布式的，数据保存在多个分片上、多台机器上，为此ES需要满足排序的需求
        - 当一个查询 from 990，size 100
            - 会在每个分片上先获取1000个文档，最后通过 Coordinating Node 聚合所有结果，最后再通过排序选出前1000个文档
            - 页数越深，占用内存就越多，为了`避免深度分页带来的内存开销`，ES默认设定分页到10000。
    - Search After 避免深度分页
        - 实时获取下一页的文档信息
            - 不支持指定页数
            - 只能往下翻
        - 第一步搜索需要指定sort，并且保证值是唯一的。
        - 然后使用上一次最后一个文档的`sort值`进行查询

            ```docker
            {
            	"query": {},
            	"search_after": [
            		13, "asdasd"
            	]
            }
            ```

- 快照 Scroll API
    - 创建一个快照，设置存活时间
        - 有新的数据写入后，无法被查到
        - 需要使用上次查询的快照的ID
    - 
- 并发控制
    - 乐观锁并发控制
        - 不会阻塞操作，如果数据在读写中被修改，更新将会失败。
        - 会将错误返回给应用程序，由应用程序决定如何解决冲突